{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from DataFidelities.pytorch_radon.radon import Radon,IRadon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from utils.util import addwgn_torch\n",
    "from math import sqrt\n",
    "import pickle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTImageMat=loadmat('CT_images_preprocessed.mat')\n",
    "CTImageArr=CTImageMat['img_cropped'][:,:,0]\n",
    "CTImageTensor=torch.tensor(CTImageArr,dtype=torch.float).unsqueeze(0).unsqueeze(0)\n",
    "theta = torch.tensor(np.linspace(0., 180, 360, endpoint=False),dtype=torch.float)\n",
    "fp=Radon(in_size=512,theta=theta,circle=False)\n",
    "sino=fp(CTImageTensor)\n",
    "noisySino,clampedNoisySino=addwgn_torch(sino,50,0,sqrt(2*512**2))\n",
    "noisySino=noisySino.detach().clone()\n",
    "clampedNoisySino=clampedNoisySino.detach().clone()\n",
    "#with open('noisyView360_clamp.pk', 'wb') as f:\n",
    "    #pickle.dump(noisySino.cpu(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullX=torch.tensor(list(itertools.product(range(noisySino.shape[2]),range(noisySino.shape[3])))).float()\n",
    "fullX[:,0]=fullX[:,0]/noisySino.shape[2]\n",
    "fullX[:,1]=fullX[:,1]/noisySino.shape[3]\n",
    "fully=noisySino.reshape((-1,1))\n",
    "X=fullX.reshape((-1,360,2))[:,::4,:].reshape((-1,2)).detach().clone()\n",
    "y=noisySino.squeeze()[:,::4].reshape((-1,1)).detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcsv=pd.DataFrame(X.numpy())\n",
    "ycsv=pd.DataFrame(y.numpy())\n",
    "Xcsv.to_csv('X.csv')\n",
    "ycsv.to_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "XFcsv=pd.DataFrame(fullX.numpy())\n",
    "XFcsv.to_csv('fullX.csv')\n",
    "yFcsv=pd.DataFrame(fully.numpy())\n",
    "yFcsv.to_csv('fully.csv')\n",
    "imagecsv=pd.DataFrame(CTImageArr)\n",
    "imagecsv.to_csv('image.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "originFullycsv=pd.DataFrame(sino.reshape(-1,1).detach().cpu().numpy())\n",
    "originFullycsv.to_csv('originFullyy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullX=torch.tensor(list(itertools.product(range(clampedNoisySino.shape[2]),range(clampedNoisySino.shape[3])))).float()\n",
    "fullX[:,0]=fullX[:,0]/clampedNoisySino.shape[2]\n",
    "fullX[:,1]=fullX[:,1]/clampedNoisySino.shape[3]\n",
    "fully=clampedNoisySino.reshape((-1,1))\n",
    "X=fullX.reshape((-1,360,2))[:,::4,:].reshape((-1,2)).detach().clone()\n",
    "y=clampedNoisySino.squeeze()[:,::4].reshape((-1,1)).detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcsv=pd.DataFrame(X.numpy())\n",
    "ycsv=pd.DataFrame(y.numpy()/sqrt(2*512**2))\n",
    "Xcsv.to_csv('XClamp.csv')\n",
    "ycsv.to_csv('yClamp.csv')\n",
    "XFcsv=pd.DataFrame(fullX.numpy())\n",
    "XFcsv.to_csv('fullXClamp.csv')\n",
    "yFcsv=pd.DataFrame(fully.numpy())\n",
    "yFcsv.to_csv('fullyClamp.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4163e3761903ec3b885c53dd89792d61078312b6005e76f7ccd5ae9bbecab266"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('torch1.6': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
